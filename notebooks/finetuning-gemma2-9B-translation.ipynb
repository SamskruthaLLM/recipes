{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-08-25T13:07:55.939275Z","iopub.status.busy":"2024-08-25T13:07:55.939006Z","iopub.status.idle":"2024-08-25T13:12:06.352611Z","shell.execute_reply":"2024-08-25T13:12:06.351422Z","shell.execute_reply.started":"2024-08-25T13:07:55.939237Z"},"trusted":true},"outputs":[],"source":["%%capture\n","!mamba install --force-reinstall aiohttp -y\n","!pip install -U \"xformers<0.0.26\" --index-url https://download.pytorch.org/whl/cu121\n","!pip install \"unsloth[kaggle-new] @ git+https://github.com/unslothai/unsloth.git\"\n","\n","!pip install datasets==2.16.0 fsspec==2023.10.0 gcsfs==2023.10.0\n","\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 2048 \n","dtype = None \n","load_in_4bit = True \n","\n","\n","fourbit_models = [\n","    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n","    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n","    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n","    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n","    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n","    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n","    \"unsloth/Phi-3-mini-4k-instruct\",          # Phi-3 2x faster!d\n","    \"unsloth/Phi-3-medium-4k-instruct\",\n","    \"unsloth/gemma-2-9b-bnb-4bit\",\n","    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n","] # More models at https://huggingface.co/unsloth\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/gemma-2-9b\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    \n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16,\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, \n","    bias = \"none\",    \n","    use_gradient_checkpointing = \"unsloth\", \n","    random_state = 3406,\n","    use_rslora = False,  \n","    loftq_config = None, \n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["alpaca_prompt = \"\"\"Below is an instruction followed by a specific question. Your goal is to provide a highly accurate and reliable answer. If you are not fully confident about the correct answer, clearly state that you are unsure or provide the most likely possibilities. Do not guess or provide potentially incorrect information.\n","\n","### Instruction:\n","Given a question in Sanskrit, provide the correct answer in Sanskrit in Devanagari only with highest possible accuracy.\n","\n","### Question:\n","{}\n","\n","### Answer:\n","{}\n","\"\"\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["EOS_TOKEN = tokenizer.eos_token \n","def formatting_prompts_func(examples):\n","    inputs       = examples[\"question\"]\n","    outputs      = examples[\"answer\"]\n","    texts = []\n","    for input, output in zip(inputs, outputs):\n","        text = alpaca_prompt.format(input, output) + EOS_TOKEN\n","        texts.append(text)\n","    return { \"text\" : texts, }\n","pass\n","\n","from datasets import load_dataset\n","dataset = load_dataset(\"SamskruthaLLM/Sanskrit-Question-Answering\", split = \"train\")\n","dataset = dataset.map(formatting_prompts_func, batched = True,)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from unsloth import is_bfloat16_supported\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, \n","    args = TrainingArguments(\n","        per_device_train_batch_size = 4,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        # num_train_epochs = 1, \n","        max_steps = 1000,\n","        learning_rate = 3e-4,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3406,\n","        output_dir = \"/kaggle/working/outputs\",\n","    ),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainer_stats = trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.save_pretrained(\"/kaggle/working/qa_gemma_model\")\n","tokenizer.save_pretrained(\"/kaggle/working/qa_gemma_model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n","model.push_to_hub_merged(\"SamskruthaLLM/gemma-2-9b-sa-qa\", tokenizer, save_method = \"merged_16bit\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5591399,"sourceId":9243212,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
